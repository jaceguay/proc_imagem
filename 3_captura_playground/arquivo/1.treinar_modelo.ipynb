{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar bibliotecas\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir parâmetros\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "LR = 1e-4\n",
    "VAL_SPLIT = 0.2\n",
    "\n",
    "# definir diretórios\n",
    "BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
    "TEST_DIR = os.path.join(DATA_DIR, 'test')\n",
    "VAL_DIR = os.path.join(DATA_DIR, 'val')\n",
    "MODEL_DIR = os.path.join(BASE_DIR, 'model')\n",
    "\n",
    "# definir classes\n",
    "CLASSES = ['with_mask', 'without_mask']\n",
    "\n",
    "# definir geradores de imagens\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir geradores\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "val_generator = test_datagen.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir modelo\n",
    "base_model = MobileNetV2(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_tensor=Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    ")\n",
    "\n",
    "head_model = base_model.output\n",
    "head_model = Flatten(name='flatten')(head_model)\n",
    "head_model = Dense(128, activation='relu')(head_model)\n",
    "head_model = Dropout(0.5)(head_model)\n",
    "head_model = Dense(1, activation='sigmoid')(head_model)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=head_model)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=Adam(lr=LR, decay=LR/EPOCHS),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir callbacks\n",
    "checkpoint = ModelCheckpoint(\n",
    "    os.path.join(MODEL_DIR, 'mask_detector.model'),\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "earlystop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint, earlystop]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treinar modelo\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(val_generator),\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# avaliar modelo\n",
    "predIdxs = model.predict(test_generator, batch_size=BATCH_SIZE)\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "\n",
    "print(classification_report(test_generator.classes, predIdxs, target_names=CLASSES))\n",
    "\n",
    "cm = confusion_matrix(test_generator.classes, predIdxs)\n",
    "total = sum(sum(cm))\n",
    "accuracy = (cm[0, 0] + cm[1, 1]) / total\n",
    "sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
    "\n",
    "print(cm)\n",
    "print('accuracy : ', accuracy)\n",
    "print('sensitivity : ', sensitivity)\n",
    "print('specificity : ', specificity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotar gráficos\n",
    "plt.style.use('ggplot')\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, EPOCHS), history.history['loss'], label='train_loss')\n",
    "plt.plot(np.arange(0, EPOCHS), history.history['val_loss'], label='val_loss')\n",
    "plt.plot(np.arange(0, EPOCHS), history.history['accuracy'], label='train_acc')\n",
    "plt.plot(np.arange(0, EPOCHS), history.history['val_accuracy'], label='val_acc')\n",
    "plt.title('Training Loss and Accuracy')\n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('Loss/Accuracy')\n",
    "plt.legend(loc='lower left')\n",
    "plt.savefig(os.path.join(MODEL_DIR, 'plot.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvar modelo\n",
    "model.save(os.path.join(MODEL_DIR, 'mask_detector.model'), save_format='h5')\n",
    "\n",
    "# salvar classes\n",
    "with open(os.path.join(MODEL_DIR, 'classes.txt'), 'w') as f:\n",
    "    f.write('\\n'.join(CLASSES))\n",
    "\n",
    "# salvar parâmetros\n",
    "with open(os.path.join(MODEL_DIR, 'params.txt'), 'w') as f:\n",
    "    f.write('IMG_SIZE = ' + str(IMG_SIZE) + '\n",
    "\n",
    "')\n",
    "    f.write('BATCH_SIZE = ' + str(BATCH_SIZE) + '\n",
    "\n",
    "')\n",
    "    f.write('EPOCHS = ' + str(EPOCHS) + '\n",
    "\n",
    "')\n",
    "    f.write('LR = ' + str(LR) + '\n",
    "\n",
    "')\n",
    "\n",
    "# salvar histórico\n",
    "with open(os.path.join(MODEL_DIR, 'history.txt'), 'w') as f:\n",
    "    f.write(str(history.history))\n",
    "\n",
    "# salvar métricas\n",
    "with open(os.path.join(MODEL_DIR, 'metrics.txt'), 'w') as f:\n",
    "    f.write('accuracy : ' + str(accuracy) + '\n",
    "\n",
    "')\n",
    "    f.write('sensitivity : ' + str(sensitivity) + '\n",
    "\n",
    "')\n",
    "    f.write('specificity : ' + str(specificity) + '\n",
    "\n",
    "')\n",
    "\n",
    "# salvar matriz de confusão\n",
    "with open(os.path.join(MODEL_DIR, 'confusion_matrix.txt'), 'w') as f:\n",
    "    f.write(str(cm))\n",
    "\n",
    "# salvar relatório de classificação\n",
    "with open(os.path.join(MODEL_DIR, 'classification_report.txt'), 'w') as f:\n",
    "    f.write(str(classification_report(test_generator.classes, predIdxs, target_names=CLASSES)))\n",
    "\n",
    "# salvar modelo em formato JSON\n",
    "model_json = model.to_json()\n",
    "with open(os.path.join(MODEL_DIR, 'model.json'), 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# salvar modelo em formato YAML\n",
    "model_yaml = model.to_yaml()\n",
    "with open(os.path.join(MODEL_DIR, 'model.yaml'), 'w') as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "\n",
    "# salvar modelo em formato HDF5\n",
    "model.save(os.path.join(MODEL_DIR, 'model.h5'))\n",
    "\n",
    "# salvar modelo em formato SavedModel\n",
    "tf.saved_model.save(model, os.path.join(MODEL_DIR, 'saved_model'))\n",
    "\n",
    "# salvar modelo em formato TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "open(os.path.join(MODEL_DIR, 'model.tflite'), 'wb').write(tflite_model)\n",
    "\n",
    "# salvar modelo em formato TensorFlow.js\n",
    "tfjs.converters.save_keras_model(model, os.path.join(MODEL_DIR, 'tfjs_model'))\n",
    "\n",
    "# salvar modelo em formato CoreML\n",
    "coreml_model = coremltools.converters.keras.convert(model)\n",
    "coreml_model.save(os.path.join(MODEL_DIR, 'model.mlmodel'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
